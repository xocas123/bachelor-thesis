llm,metric,value,valid_entries
grok,funniness,4.229488639444716,55323
grok,offensiveness,2.8007266023207893,55326
grok,originality,5.02700357878755,55326
grok,appropriateness,7.15567725843184,55326
grok,clarity,6.717859662451837,55281
deepseek,funniness,4.955322669608384,59829
deepseek,offensiveness,3.1047986762272477,59829
deepseek,originality,5.327834327834328,59829
deepseek,appropriateness,6.846161560447275,59829
deepseek,clarity,7.790051647194504,59829
chatgpt,funniness,4.868043052054575,74979
chatgpt,offensiveness,1.9419037330452527,74979
chatgpt,originality,4.350898251510423,74979
chatgpt,appropriateness,6.646060897051174,74979
chatgpt,clarity,7.955547553314928,74979
average,funniness,4.709705413635861,190131
average,offensiveness,2.5577329672757108,190134
average,originality,4.855044337151693,190134
average,appropriateness,6.857316418946637,190134
average,clarity,7.543519088427,190089
